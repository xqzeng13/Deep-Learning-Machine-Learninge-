### 机器学习&深度学习

**深度学习可以自行完成特征提取过程而机器学习需要人工来处理特征内容**

**全卷积网络相较于普通CNN网络，在处理图像时的优势在于*<u>不必限制图片输入的尺寸一致</u>***

## 一、机器学习



- [x] #### 生成式模型和判别模型：

  **生成式模型：**

1. 朴素贝叶斯模型：基于贝叶斯定理，用于文本分类、垃圾邮件过滤等任务。
2. 隐马尔可夫模型（HMM）：用于序列数据建模，如语音识别、自然语言处理中的词性标注等。
3.  高斯混合模型（GMM）：通过多个高斯分布的线性组合来近似复杂数据分布，常用于**聚类**和图像分割，采用**期望最大化准则**训练。
4. 变分自编码器（VAE）：一种用于学习数据分布的神经网络模型，可以用于生成图像、文本等。
5. 生成对抗网络（GAN）：由生成器和判别器组成的框架，用于生成逼真的样本，如图像、音频等。
6. 马尔可夫随机场（MRF）：用于图像分割、计算机视觉等领域，可以建模像素之间的关系。
7. 贝叶斯网络：用于建模变量之间的条件概率关系，常用于推断潜在的因果关系

​		**判别模型：**

1. 决策树
2. 支持向量机
3. 最大熵模型
4. 逻辑回归模型

- [x] #### 无监督和有监督模型

  **无监督模型：**

  高斯混合模型（GMM）、

  **有监督模型：**

- [x] #### 关于随机森林(RF)与GBDT的表述正确的是:

- RF并行建立模型，模型与模型之间并没有太强的依赖;
- RF是通过减小方差，来提高泛化能力;
- GBDT可以自动筛选特征

- [x] #### Bagging 和Boosting

​	**Bagging：**通过合并多个模型降低泛化误差的方法，Bagging方法中所有分类器权重相同，能够降低模型的方差，即总分类器对数据扰动的承受能力更好，从而改善模型过拟合问题。 

​	**Boosting**：能够降低模型的偏差，改善模型的欠拟合问题;Boosting 将基分类器层层叠加，实现串行训练

- [x] #### XGBoost和LightGBM模型

- ​	XGBoost的直方图并不是针对某个特定的特征，而是所有特征都共享一个直方图，因此每层都需要动态构建直方图。而LightGBM的直方图每个特征只有一个直方图，因此只需要构建一次直方图；
- ​	Block结构正是XGBoost速度慢的一个重要因素，它通过索引来获取梯度，而这些梯度的获取顺序是按照特征的大小顺序的，这将导致非连续的内存访问，可能使得缓存命中率低，从而影响算法效率。而LightGBM是基于直方图分裂特征的，梯度信息都存储在一个个bin中，所以访问梯度是连续的，缓存命中率高；
- ​	XGBoost采用level-wise的分裂策略，LightGBM采用leaf-wise的分裂策略；
- ​	在大数据量下，LightGBM中先对数据水平切分，每个worker上的数据先建立起局部的直方图，然后合并成全局的直方图。采用直方图相减的方式，先计算样本量少的节点的样本索引，然后直接相减得到另一子节点的样本索引，因此大大降低了worker间的通信成本，因为只用通信这些样本量少的节点。XGBoost中的数据并行也是水平切分，然后单个worker建立局部直方图，再合并为全局，不同在于根据全局直方图进行各个worker上的节点分裂时会单独计算子节点的样本索引，因此效率很低，每个worker间的通信量非常大

- [x] #### ID3和C4.5算法

- ​	信息增益最大化是ID3算法选择划分属性的准则，信息增益率最大化是C4.5算法选择划分属性的准则。
- ​	C4.5算法的运行速度相比ID3算法会慢一些
- ​	工程中C4.5算法经常启发式的去选择特征，先从候选特征中找出信息增益高于平均水平的，然后再从这些特征中找出信息增益率最高的

- [x] #### 机器学习优化算法：

**梯度下降算法和牛顿法**

- ​	牛顿法求解需要的迭代次数比梯度下降算法少
- ​	牛顿法每次训练迭代都需要计算Hessian矩阵的逆，运算量大
- ​	梯度下降算法靠近极小值时收敛速度减慢

**LDA(Latent Dirichlet allocation)**：



| 机器学习模型                                      | 概念                                                         | 图解                                                         | 使用场景                                                     |
| ------------------------------------------------- | :----------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 线性回归 Linear Regression                        | 线性回归**<u>是一种用于建立连续目标变量与自变量之间线性关系的模型。</u>**它通过拟合一个线性方程，将自变量与目标变量之间的关系表示为直线或超平面。线性回归的目标是找到最佳的拟合线，使得观测值与预测值之间的残差平方和最小化。线性回归可以用于预测和探索性数据分析<br/>线性回归又分为两种类型，即 **简单线性回归（simple linear regression)**，只有 1 个自变量；\*多变量回归（multiple regression)，至少两组以上自变量 | ![img](https://pic3.zhimg.com/80/v2-b55226e2ae1f1d8cca9b2388c7d691ba_720w.webp) |                                                              |
| 逻辑回归  Logistic Regression **LR**              | 逻辑回归<u>**是一种用于建立分类模型的算法。它通过拟合一个逻辑函数，将自变量与目标变量之间的关系表示为概率**</u>。逻辑回归的<u>**目标是找到最佳的拟合曲线，使得观测值属于某个类别的概率最大化**</u>。逻辑回归常用于二分类问题，但也可以扩展到多分类问题。逻辑回归的输出是一个概率值，可以根据设定的阈值进行分类。<br />逻辑回归算法（Logistic Regression）一般用于需要明确输出的场景，如某些事件的发生（预测是否会发生降雨）。通常，逻辑回归使用某种函数将概率值压缩到某一特定范围。<br/>例如，右图Sigmoid 函数（S 函数）是一种具有 S 形曲线、用于二元分类的函数。它将发生某事件的概率值转换为 0, 1 的范围表示 | ![img](https://pic2.zhimg.com/80/v2-d12903834c27c4bb1f69c9f03b3e0821_720w.webp) |                                                              |
| 随机森林 Random Forest **RF**                     | 随机森林可以**<u>看作一个决策树的集合</u>**。随机森林中每棵决策树估计一个分类，这个过程称为“投票（vote）”。理想情况下，我们根据每棵决策树的每个投票，选择最多投票的分类。**<u>随机森林对数据集进行有放回的抽样（bootstrap sampling），并对每个抽样集构建一个决策树。在构建决策树时，随机森林会随机选择一部分特征进行划分，以减小各个决策树之间的相关性。最后，随机森林通过投票或平均等方式将多个决策树的结果集成，得到最终的预测结果</u>** | <img src="https://pic3.zhimg.com/80/v2-7e183bf8a379c838b39b286a0c76451e_720w.webp" alt="img" style="zoom:200%;" /> | **随机森林算法属于Bagging，梯度提升决策树是Boosting算法中流行的模型** |
| 决策树 Decision Tree  **DT**                      | 是一种基于树状结构的机器学习算法。**<u>它通过对数据集进行递归地二分划分，构建一棵树，每个内部节点表示一个特征，每个叶节点表示一个类别。决策树的构建过程是根据数据集中的特征选择最佳的划分方式，使得划分后的子集纯度最大化</u>**。由一个决策图和可能的结果（例如成本和风险）组成，用来辅助决策。机器学习中，决策树是一个预测模型，树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树**仅有单一输出**，通常该算法用于解决分类问题 | ![img](https://pic4.zhimg.com/80/v2-0f69518174548e4cef1125855efb264f_720w.webp) | 确定人群中谁喜欢使用信用卡。考虑人群的年龄和婚姻状况，如果年龄在30岁或是已婚，人们更倾向于选择信用卡，反之则更少 |
| 支持向量机（Support Vector Machine **SVM**）      | 属于分类型算法。SVM模型将实例表示为空间中的点，将使用一条直线分隔数据点。需要注意的是，支持向量机需要对输入数据进行**完全标记**，仅直接适用**于两类任务**，应用将多类任务需要减少到几个二元问题。<br />SVM是一种**<u>二分类模型</u>**，其<u>目标**是找到一个最优的超平面，将不同类别的样本分开**</u>。SVM通过将样本映射到高维特征空间，使得样本在特征空间中线性可分。在特征空间中，SVM选择一个最优的超平面，使得离超平面最近的样本点到该超平面的距离最大化，这些样本点被称为支持向量。SVM的预测是根据样本点在超平面上的投影位置来判断其类别。对于线性不可分的情况，SVM可以通过使用核函数将样本映射到更高维的特征空间来实现非线性分类。 | ![img](https://pic1.zhimg.com/80/v2-e6d81ca4c81d7b8545b4fe4744451834_720w.webp) |                                                              |
| 最近邻居/k-近邻算法 (K-Nearest Neighbors,**KNN**) | 是一种基于实例的学习，或者是局部近似和将所有计算推迟到分类之后的惰性学习。用最近的邻居（k）来预测未知数据点。k 值是预测精度的一个关键因素，无论是分类还是回归，衡量邻居的权重都非常有用，较近邻居的权重比较远邻居的权重大。KNN 算法的缺点是对数据的局部结构非常敏感。计算量大，需要对数据进行规范化处理，使每个数据点都在相同的范围 | ![img](https://pic1.zhimg.com/80/v2-4049dfe6d396441e3bbda4438486677c_720w.webp) |                                                              |
| 朴素贝叶斯（Naive Baues）**NB**                   | 基于概率论的贝叶斯定理，应用非常广泛，从文本分类、垃圾邮件过滤器、医疗诊断等等。朴素贝叶斯适用于特征之间的相互独立的场景，例如利用花瓣的长度和宽度来预测花的类型。“朴素”的内涵可以理解为特征和特征之间独立性强 |                                                              | 建立人口身高模型，很难有人力与物力去统计全国每个人的身高，但是可以通过采样，获取部分人的身高，然后通过最大似然估计来获取分布的均值与方差 |
| 降维算法（Dimensional reduction）**DR**           | 是指在限定条件下，降低随机变量个数，得到一组“不相关”主变量的过程，并可进一步细分为特征选择和特征提取两大方法 |                                                              | 一些数据集可能包含许多难以处理的变量。特别是资源丰富的情况下，系统中的数据将非常详细。在这种情况下，数据集可能包含数千个变量，其中大多数变量也可能是不必要的。在这种情况下，几乎不可能确定对我们的预测影响最大的变量。此时，我们需要使用降维算法，降维的过程中也可能需要用到其他算法，例如借用随机森林，决策树来识别最重要的变量 |
| 梯度增强算法 Gradient Boosting                    | 使用多个弱算法来创建更强大的精确算法。它与使用单个估计量不同，而是使用多个估计量创建一个更稳定和更健壮的算法。 |                                                              | 梯度增强算法的特点是精度较高。此外，LightGBM 算法具有令人难以置信的高性能 |
| 1-XGBoost                                         |                                                              | **缺失值特征：**XGBoost和LightGBM都可以自动处理特征缺失值。<br />**分类特征：**XGBoost不支持类别特征，需要OneHot编码预处理。LightGBM直接支持类别特征。 | **模型精度：**XGBoost和LightGBM相当。<br />**训练速度：**LightGBM远快于XGBoost。(快百倍以上，跟数据集有关系)<br />**内存消耗：**LightGBM远小于XGBoost。(大约是xgb的五分之一) |
| 2-LightGBM                                        |                                                              | ***速度快：<br />***LightGBM 采用了直方图算法将遍历样本转变为遍历直方图，极大的降低了时间复杂度；<br/>LightGBM 在训练过程中采用单边梯度算法过滤掉梯度小的样本，减少了大量的计算；<br/>LightGBM 采用了基于 Leaf-wise 算法的增长策略构建树，减少了很多不必要的计算量；<br/>LightGBM 采用优化后的特征并行、数据并行方法加速计算，当数据量非常大的时候还可以采用投票并行的策略；<br/>LightGBM 对缓存也进行了优化，增加了 Cache hit 的命中率 | ***内存小<br />***XGBoost 使用预排序后需要记录特征值及其对应样本的统计值的索引，而 LightGBM 使用了直方图算法将特征值转变为 bin 值，且不需要记录特征到样本的索引，将空间复杂度从 <br/> 降低为 <br/> ，极大的减少了内存消耗；<br/>LightGBM 采用了直方图算法将存储特征值转变为存储 bin 值，降低了内存消耗；<br/>LightGBM 在训练过程中采用互斥特征捆绑算法减少了特征数量，降低了内存消耗 |
| 集成机器学习算法Bootstrap Aggregation（Bagging）  | 估计整个统计模型                                             | <img src="https://img-blog.csdnimg.cn/20181210111927204.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjAwMTA4OQ==,size_16,color_FFFFFF,t_70" alt="img" style="zoom:500%;" /> | 其主要的伎俩核心其实在于抽样方法，例如bootstrap aggregating<br/>1）每轮从原始样本集中使用Bootstraping的方法抽取n个训练样本（有放回的抽取，即有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中）.共进行k轮抽取，得到k个训练集.（k个训练集相互独立）<br />2）每次使用一个训练集去训练得到一个模型，k个训练集共得到k个模型.（具体到用什么模型可以根据具体问题而定）<br/>3）预测结果：对分类问题便是将上述得到的k个模型采用投票的方式得到分类结果；对回归问题变数计算上述模型的均值作为最后的结果. <br/> |
| Boosting                                          | 试图集成一些弱分类器来创建一个强分类器。这通过从训练数据中构建一个模型，然后创建第二个模型来尝试纠正第一个模型的错误来完成。一直添加模型直到能够完美预测训练集，或添加的模型数量已经达到最大数量 |                                                              |                                                              |
| AdaBoost                                          | AdaBoost 是最小化指数损失函数，并迭代式地在加权的数据上训练弱学习器第一个为二分类开发的真正成功的 boosting 算法。这是理解 boosting 的最佳起点。现代 boosting 方法建立在 AdaBoost 之上，最显著的是随机梯度提升 | 分类特征：XGBoost不支持类别特征，需要OneHot编码预处理。LightGBM直接支持类别特征。 |                                                              |
| 神经网络（neural networks **nn**)                 |                                                              |                                                              |                                                              |
| Lasso                                             | Lasso特征选择（Lasso Feature Selection）是一种用于<u>**选择最相关特征的方法**</u>，它结合了**<u>线性回归和L1正则化</u>**。Lasso回归通过最小化目标函数，同时考虑了拟合误差和特征的绝对值之和. | Lasso回归的特点是它的正则化项（L1范数）可以使得一部分回归系数变为0，从而实现特征选择。通过调整正则化参数alpha的值，可以控制特征选择的程度。当alpha较大时，Lasso回归倾向于将不相关的特征系数置为0，从而选择出最相关的特征。而当alpha较小时，Lasso回归的效果接近于无正则化的线性回归。 | Lasso特征选择的优点是它**<u>可以自动选择最相关的特征，减少了特征维度，提高了模型的解释性和泛化能力。它还可以帮助排除冗余特征，减少过拟合的风险</u>**。然而，Lasso特征选择也有一些注意事项，例如在特征之间存在高度共线性时，Lasso可能会随机选择其中一个特征，而忽略其他相关特征。此外，Lasso对于大规模数据集的计算复杂度较高，需要耗费较多的时间和计算资源。 |
|                                                   |                                                              |                                                              |                                                              |

## **二、深度学习**

**（卷积计算，BN/IN/LN,经典模型（VGG,Alex-Net,Res-Net,KNN））**

### 1.卷积计算：

1）**卷积尺寸**计算：
$$
**o = [ (i + 2p - k) / s]  + 1**
$$
其中**o**为输出尺寸；**i** 为输入尺寸；**p**为padding; **k**为卷积核大小；**s**为步长stride.



2）**感受野计算**：

​		假如输入尺寸为24×24, 3个5×5卷积核（默认padding 为1，stride为1）得到的输出尺寸为，
$$
24-5+1=20,20-5+1=16,16-5+1=12
$$
。就相当于24-13+1=12，也就是3个5×5卷积核可以替换13×13的卷积核。 

3）**稠密矩阵计算效率**：

计算三个稠密矩阵 A、B、C 的乘积 ABC，假定三个矩阵的尺寸分别为 

```
m*n, n*p,p*q，且 m<n<p<q,
```

以下计算效率最高的是

- ```
  (AB)C
  ```

- ```
  A(BC)
  ```

- ```
  (AC)B
  ```

- ```
  (BC)A
  ```

- ```
  (CA)B
  ```

分析：![img](https://uploadfiles.nowcoder.com/images/20170924/6206174_1506244800688_ADC346420E5DF1A12792CAB3B3DAE054)



### 2.归一化

**（Batch Nor,Instans Nor, Layer Nor,Group Nor）**

正则化：正则化项可以用来降低模型的复杂度，防止过拟合.

**L1&L2:**

- ​	L1范数表示绝对值的和，L2范数表示平方和的平方根;
- ​	L1范数是L0范数的最优凸近似，即L1范数可以作为L0范数的替代来进行特征选择;
- ​	L0范数是非凸的，优化求解困难，而L1范数是凸的，可以通过各种优化算法进行求解
- ​	L1范数可以将某些特征的权重变为零，从而实现特征选择的作用
- ​    使用L1可以得到稀疏的权值；使用L2可以得到平滑的权值

1.**Batch Nor**  输入:<u>B C W H D ;输出均值形状为：1 C 1 1 1</u>





![img](https://img-blog.csdnimg.cn/20210319221042880.png)



### 3.经典模型：

**Transformer**的decoder中的 multi-head attention，Q , K , V . → → →**Q 来自decoder，K、V来自encoder**

#### 1)VGG

**拟解决的问题：**VGG通过采用更深的网络结构来解决梯度消失问题。它使用了多个3x3的卷积层和池化层的连续堆叠，使得网络的深度增加。相比于使用更大的卷积核或池化核，采用多个小的卷积核可以增加网络的深度，并且具有更少的参数量。这种设计使得VGG可以构建非常深的网络。它的网络结构非常简洁和规整。VGG网络中只使用了卷积层、池化层和全连接层，没有使用复杂的网络模块，如残差连接等。这种简洁的结构使得VGG易于理解和实现，并且可以在不同的任务中进行迁移学习

应用场景：**VGG适用于处理小规模图像数据集、要求较高的细粒度特征提取和图像风格转换等任务**。

1. VGG拥有较简单的网络结构，层数相对较浅，容易理解和实现，适合初学者入门深度学习。
2. VGG采用了较小的卷积核和更深的网络结构，能够提取更细粒度的图像特征，因此在图像风格转换、图像生成等任务中表现出色。
3. VGG在处理小规模图像数据集时也能取得较好的效果，常被用于图像分类、目标检测等任务。

![VGG模型学习_pinn山里娃的博客-CSDN博客_vgg模型训练](https://img-blog.csdnimg.cn/2020041318194978.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTUyMTU5NA==,size_16,color_FFFFFF,t_70)

#### 2）Res Net(18) 

##### **拟解决的问题：**

解决梯度消失和梯度爆炸问题：随着网络层数的增加，梯度在反向传播过程中逐渐变小，导致网络难以训练。这是由于深层网络中的层与层之间的映射关系变得复杂，难以直接拟合。梯度消失的问题使得网络的训练效果变差，难以收敛到最优解。即使网络层数很深，梯度可以通过**<u>短路路径</u>**直接传递到较浅的层，从而避免了梯度的消失和爆炸问题。

##### **应用场景：** 

**ResNet适用于处理大规模图像数据集、要求较高准确性和泛化能力的任务**

1. RESNET具有非常深的网络结构，能够处理更复杂的图像特征，因此在图像识别、目标检测和语义分割等任务中表现出色。
2. RESNET采用了残差连接（residual connection）的设计，解决了深层网络梯度消失和梯度爆炸的问题，使得网络的训练更加稳定。
3. RESNET在处理大规模图像数据集时具有较高的准确性和泛化能力，常被用于图像分类、人脸识别等任务。

##### **原理结构：**（经过2个卷积后加回输入特征，再通过stide 尺寸减半，同时特征通道加倍）

![resnet18与resnet50_resnet18和resnet50_正则化的博客-CSDN博客](https://img-blog.csdnimg.cn/20191128165045833.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTUxOTQ2Mw==,size_16,color_FFFFFF,t_70)

#### 3）Transformer:

##### 拟解决问题：

基于自注意力机制的序列建模方法。它主要解决了传统的循环神经网络（RNN）在处理长序列数据时存在的一些问题（传统的RNN在处理长序列数据时，存在梯度消失和梯度爆炸的问题，导致难以捕捉长距离的依赖关系。此外，RNN是顺序处理的，每个时间步的计算必须依赖前面所有时间步的计算结果，无法进行并行计算，限制了模型的训练速度。），并在自然语言处理领域取得了重大突破。

##### 原理：

- Transformer模型通过引入**自注意力机制**（self-attention）来解决上述问题。自注意力机制可以在序列中的任意两个位置之间建立关联，从而捕捉长距离的依赖关系。它通过计算每个位置与其他位置的相关性，根据相关性权重对不同位置的表示进行加权求和。这样，每个位置都可以直接获取到序列中其他位置的信息，避免了梯度消失和梯度爆炸问题。
- 模型还引入了**多头注意力机制**（multi-head attention），进一步提升了模型的表示能力。多头注意力机制将自注意力机制应用多次，并在每次应用中使用不同的参数，从而学习到多个不同的表示。这样可以捕捉到不同层次和不同类型的语义信息，提高了模型的表达能力。
- 模型还使用了**位置编码**（position encoding）来保留序列中的顺序信息。位置编码是将序列中每个位置的绝对位置信息编码成一个向量，与词向量相加后作为输入。这样可以使模型在处理序列数据时保持了一定的顺序感。

#### 4）Swin Transformer

##### **拟解决问题：**

解决了传统的Transformer模型在处理大尺寸图像时存在的计算和内存开销问题，并在图像分类任务上取得了优秀的性能。

##### **原理：**

- 传统的Transformer模型在处理图像时，需要将图像划分成较小的图块，并将每个图块作为序列输入到Transformer中。然而，这种方法在处理大尺寸图像时会导致较高的计算和内存开销，限制了模型的规模和性能。
- Swin Transformer通过引入**分层的注意力机制**（hierarchical attention）来解决上述问题。它将图像划分成多个不同层次的图块，每个层次的图块都可以进行并行计算，从而降低了计算和内存开销。在每个层次的图块内部，使用了普通的Transformer模型进行特征提取和建模。
- 此外，Swin Transformer还引入了**局部注意力窗口**（local attention window）的概念。在每个层次的图块内，只考虑局部区域内的注意力关系，而不是全局的注意力关系。这样可以进一步降低计算和内存开销，并且能够保持模型对局部细节的感知能力。
- Swin Transformer还使用了**跨层连接**（cross-layer connection）来促进信息的传递和流动。在每个层次的图块内，将上一层的输出与当前层的输入进行残差连接，使得信息可以更好地在不同层次之间传递和交流。

## 三、公共指标

（评价指标，损失函数，激活函数，优化器）

### 1.评价指标：

(1)小米有品推荐的商品有多少是用户喜欢的？**精确率(Precision)**

(2)用户喜欢的商品有多少被小米有品推荐了？**召回率(Recall)**

| ***<u>分类任务</u>***              | 概念                                                         | 公式                                                         | 优缺点                                                       |
| ---------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **准确率（Accuracy）**             | 识别对了的正例（TP）与负例（TN）占总识别样本的比例           | ![image-20230918165416180](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918165416180.png) | **缺点：类别比例不均衡时影响评价效果**                       |
| **精确率(Precision)**              | 识别正确的正例（TP）占识别结果为正例（TP+FP）的比例          | ![image-20230918165453273](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918165453273.png) | **Precision**和**Recall**是一对矛盾又统一的指标，当分类**阈值越高**时，模型的**精确率越高**，相反**召回率越低**。 |
| **召回率(Recall)**                 | **识别正确的正例（TP）占实际为正例（TP+FN）的比例**          | **![image-20230918165508285](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918165508285.png)** |                                                              |
| **F1**                             | 是召回率Recall和精度Pre的加权调和平均，顾名思义即是为了调和召回率R和精度P之间增减反向的矛盾，对R和P进行加权调和 | <img src="C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918165638800.png" alt="image-20230918165638800" style="zoom: 200%;" /> |                                                              |
| **P-R**                            | PR曲线通过取不同的分类阈值，分别计算当前阈值下的模型P值和R值，以P值为纵坐标，R值为横坐标，将算得的一组P值和R值画到坐标上，就可以得到P-R曲线。**当一个模型的P-R曲线完全包住另一个模型的P-R曲线，则前者的性能优于后者（如A>C，B>C)** | ![img](https://pic2.zhimg.com/v2-121d795d558e02f7c082ada9f7864c55_r.jpg) |                                                              |
| **ROC**                            | ROC曲线也称受试者工作特征。以FPR（假正例率：假正例占所有负例的比例）为横轴，TPR（召回率）为纵轴，绘制得到的曲线就是ROC曲线。**与PR曲线相同，曲线下方面积越大，其模型性能越好。** | ![img](https://pic3.zhimg.com/v2-41bec97976f4099905dc5e06f1f84bf6_r.jpg) |                                                              |
| **AUC**                            | ROC曲线下的面积即为AUC。面积越大代表模型的分类性能越好       | ![image-20230918165859696](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918165859696.png) |                                                              |
|                                    |                                                              |                                                              |                                                              |
| ***<u>回归任务</u>***              | **概念**                                                     | **公式**                                                     | **优缺点**                                                   |
| **MAE(Mean Absolute Error)**       | MAE是平均绝对误差，又称L1范数损失。通过计算预测值和真实值之间的距离的绝对值的均值，来衡量预测值与真实值之间的真实距离。 | ![image-20230918170039459](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918170039459.png) |                                                              |
| **MSE（Mean Square Error）**       | MSE是真实值与预测值的差值的平方然后求和平均。通过平方的形式便于求导，所以常被用作线性回归的损失函数 | ![image-20230918170151847](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918170151847.png) |                                                              |
| **RMSE（Root Mean Square Error）** | RMSE衡量观测值与真实值之间的偏差。常用来作为机器学习模型预测结果衡量的标准。 | ![image-20230918170209065](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918170209065.png) | **受异常点影响较大，鲁棒性比较差。**                         |
|                                    |                                                              |                                                              |                                                              |
| <u>***排序任务***</u>              | **概念**                                                     | **公式**                                                     | **优缺点**                                                   |
| **AUC**                            |                                                              |                                                              |                                                              |
| **MAP（Mean Average Precision）**  | 全局平均准确率，其中AP表示单用户TopN推荐结果的平均准确率。   | ![image-20230918170339832](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918170339832.png)![image-20230918170357376](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918170357376.png) |                                                              |
| **NDCG**                           | 首先介绍CG（累计收益），模型会给推荐的每个item打分表示与当前用户的相关性。假设当前推荐item的个数为N个，我们把这N个item的相关分数进行累加，就是当前用户的累积增益;显然CG不考虑不同位置对排序效果的影响，所以在此基础上引入**位置影响因素**，即DCG（折损累计增益），位置靠后的结果进行加权处理： | ![image-20230918170427752](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918170427752.png)![image-20230918170433631](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918170433631.png) | **推荐结果的相关性越大，DCG越大，推荐效果越好。**            |

#### 2.损失函数：

| **分类损失函数**                                | 概念                                                         | 公式                                                         |                                                              |
| ----------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **0-1损失函数(zero-one loss)**                  | 0-1损失是指预测值和目标值不相等为1， 否则为0。是一个非凸函数，不可导，不适用 | ![image-20230918170641083](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918170641083.png) |                                                              |
| **交叉熵损失（Cross-entropy loss function）**   | 交叉熵损失函数经常用于分类问题中，特别是在神经网络做分类问题时，也经常使用交叉熵作为损失函数。**交叉熵损失函数的输入数据通常是softmax或者sigmoid函数的输出。** | <img src="C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918170740055.png" alt="image-20230918170740055" style="zoom:400%;" /> | <img src="C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918170753002.png" alt="image-20230918170753002" style="zoom:500%;" /> |
| **log对数损失函数（logarithmic loss）**         | 对数损失函数本质上是一种**似然函数**，主要在**逻辑回归**中使用。假设样本预测值和实际值的误差符合高斯分布，采用极大似然估计的方法，取对数得到损失函数 | ![image-20230918170843840](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918170843840.png) | **对数损失函数的健壮性不强，对噪声敏感。对数损失函数和交叉熵损失函数是等价的（推导路径不一致）。**交叉熵中未知真实分布相当于对数损失中的真实标记y，寻找的近似分布相当于对数损失的预测值。<br />区别：**交叉熵函数**描述模型预测值和真实值的差距大小，越大代表越不相近；**似然函数**衡量在某个参数下，整体的估计和真实样本一致的概率，越小代表越不相近。<br />联系：**交叉熵函数**可以由最大似然函数在伯努利分布的条件下推导出来，或者说**最小化交叉熵函数**的本质就是**对数似然函数的最大化** |
| **指数损失函数（exponential loss）**            | y 代表真实标记， f(x)代表模型预测值，**指数损失函数对噪声数据十分敏感**。通常用在集成学习中。 | ![image-20230918171029191](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918171029191.png) |                                                              |
| **合页损失函数(Hinge loss)**                    | hinge损失函数中样本如果被正确分类，则损失为0，否则损失就为 1−y*f(x) 。**支持向量机SVM**使用hinge损失函数 | ![image-20230918171125071](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918171125071.png) | 合页损失不仅惩罚预测错的样本，对于预测对了但是置信度不高的样本数据也会给予一定的惩罚，只有置信度高的才会有零损失。**健壮性相对较高，对异常点、噪声不敏感** |
|                                                 |                                                              |                                                              |                                                              |
| **回归损失函数**                                | 概念                                                         | 公式                                                         |                                                              |
| **绝对值损失函数（ Mean Absolute Error，MAE）** | **平均绝对误差即L1损失函数**，平均绝对误差指的就是模型预测值 f(x) 与样本真实值 y 之间距离的平均值。 | ![image-20230918171235480](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918171235480.png) | MAE 大部分情况下梯度都是相等的，这意味着即使对于小的损失值，其梯度也是大的。**不利于函数的收敛和模型的学习。** |
| **平方损失函数（Mean Square Error，MSE）**      | **均方误差即L2损失**，均方误差指的就是模型预测值 f(x) 与样本真实值 y 之间距离**平方**的平均值 | ![image-20230918171300047](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918171300047.png) | **MSE 曲线的特点是光滑连续、可导**，**便于使用梯度下降算法**，是比较常用的一种损失函数。而且，MSE 随着误差的减小，梯度也在减小，这有利于函数的收敛。 |
| **Huber Loss**                                  | Huber Loss 结合了 MSE 和 MAE 损失，**在误差接近 0 时使用 MSE，使损失函数可导并且梯度更加稳定；在误差较大时使用 MAE 可以降低噪声数据的影响**，使训练对 outlier 更加健壮。缺点是需要额外地设置一个δ超参数 | ![image-20230918171331409](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918171331409.png) |                                                              |
| **Focal loss**                                  |                                                              |                                                              |                                                              |
| **Dice loss**                                   |                                                              |                                                              |                                                              |
| **BCE loss**                                    |                                                              |                                                              |                                                              |

#### 3.优化器：

| 优化器                             | 概念                                                         | 公式                                                         | 图例                                                         |
| ---------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **梯度下降法（gradient descent）** | 选择最陡峭的地方下山——这是梯度下降法的核心思想：它通过每次在当前梯度方向（最陡峭的方向）向前“迈”一步，来逐渐逼近函数的最小值；<br />梯度下降法根据每次求解损失函数LL带入的样本数，可以分为：**全量梯度下降**（计算所有样本的损失）**，批量梯度下降**（每次计算一个batch样本的损失）**和随机梯度下降**（每次随机选取一个样本计算损失）<br />**缺点：**  **学习率设定问题**，如果学习速率过小，则会导致收敛速度很慢。如果学习速率过大，那么其会阻碍收敛，即在极值点附近会振荡。 **模型所有的参数每次更新都是使用相同的学习速率。** **陷入局部最小值和鞍点。** | ![image-20230918171754266](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918171754266.png) | <img src="https://pic2.zhimg.com/v2-5fad80ff8aaa4bfa8da8e5b385351819_r.jpg" alt="img" style="zoom:150%;" /> |
| **Momentum**                       | 为了解决随体梯度下降上下波动，收敛速度慢的问题，提出了Momentum优化算法，这个是基于SGD的，简单理解，就是为了防止波动，取前几次波动的平均值当做这次的W<br />**缺点： ** **依旧使用同一学习率alpha**，比较难学习一个较好的学习率 | ![image-20230918173501040](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918173501040.png) | ![img](https://pic2.zhimg.com/80/v2-5fad80ff8aaa4bfa8da8e5b385351819_720w.webp) |
| **Adagrad**                        | 在前面介绍的算法中，每个模型参数θi使用相同的学习速率η，而Adagrad在每一个更新步骤中对于每一个模型参数θi使用不同的学习速率ηi。<br />**缺点：** **梯度衰减问题，**Gt是不断增加的，导致学习率不断衰减，最终变得非常小 | <img src="C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918173603946.png" alt="image-20230918173603946" style="zoom:200%;" /> |                                                              |
| **RMSprop**                        | RMSprop使用指数加权平均来代替历史梯度的平方和                | ![image-20230918173658321](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918173658321.png) | <img src="https://pic1.zhimg.com/80/v2-571af52ad6ce9ecb796c523dab33c674_720w.webp" alt="img" style="zoom:150%;" /> |
| **Adam**                           | Adam是Momentum 和 RMSprop的结合，被证明能有效适用于不同神经网络，适用于广泛的结构。是目前最常用的优化方法，优势明显.<br /><br />数据量小可以用SGD。 稀疏数据则选择自适应学习率的算法；而且，只需设定初始学习率而不用再调整即很可能实现最好效果。 Adagrad, Adadelta, RMSprop, Adam可以视为一类算法。RMSprop 与 Adadelta本质相同，都是为了解决Adagrad的学习率消失问题。 目前来看，无脑用 Adam 似乎已经是最佳选择 | 1.Adam 在计算过程中同样利用到了梯度二阶矩，在不稳定 (Non-Stationary) 的目标函数下，比基本的 SGD、Momentum、AdaGrad 表现更优秀；<br />2. Adam 优化算法在梯度下降的过程中同时了利用梯度的一阶矩估计和二阶矩估计；<br />3.属于自适应学习率优化算法 |                                                              |
| **SGD**                            |                                                              |                                                              |                                                              |
|                                    |                                                              |                                                              |                                                              |
|                                    |                                                              |                                                              |                                                              |

#### 4.激活函数：

 ReLU 激活函数和 tanh 激活函数：

- ​	相比于 tanh 激活函数，ReLU 函数的非饱和性可以一定程度上防止梯度消失；
- ​	负梯度会被 ReLU 激活函数控制为 0，因此可能导致部分神经元死亡；
- ​	ReLU 的单侧抑制提供了一定程度上防止过拟合的能力；
- ​	tanh 函数需要指数计算，复杂度比 ReLU 更高

| 激活函数       |      | 公式                                                         | 图例                                                         | 特性                                                         |
| -------------- | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **sigmoid**    |      | <img src="C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918174046809.png" alt="image-20230918174046809" style="zoom:150%;" /> | ![img](https://pic2.zhimg.com/80/v2-707f1aa66391f2a838fd3b81c93d45d5_720w.webp) | 输出范围是 0 到 1；<br />梯度平滑，避免「跳跃」的输出值；<br />函数是可微的。 |
| **softmax**    |      |                                                              |                                                              |                                                              |
| **tanh**       |      | <img src="C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918174219911.png" alt="image-20230918174219911" style="zoom:150%;" /> | ![img](https://pic1.zhimg.com/80/v2-2e4c92ede47e719d0ce54653b2f443d8_720w.webp) | 在一般的二元分类问题中:<br />tanh 函数用于隐藏层，<br />sigmoid 函数用于输出层 |
| **Relu**       |      | ![image-20230918174337789](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918174337789.png) | ![img](https://pic3.zhimg.com/80/v2-8505da32b28e52b61772f04fbcc3c9a2_720w.webp) | 当输入为正时，导数为1，<br />一定程度上改善了梯度消失问题，<br />加速梯度下降的收敛速度;<br />计算速度快;<br />当输入为负时，ReLU 完全失效;<br />引入偏置偏移 |
| **Prelu**      |      | ![image-20230918175019680](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918175019680.png) | ![img](https://pic3.zhimg.com/80/v2-a942719eba0ee2d65db0a8a030d280ba_720w.webp) | γ 是超参数，对应了 x≤0 时函数的斜率。<br />引入了一个随机科学系的超参数，<br />可根据γ值退化成变成 ReLU 或 Leaky ReLU。 |
| **Leaky Relu** |      | ![image-20230918174501072](C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918174501072.png) | ![img](https://pic3.zhimg.com/80/v2-a942719eba0ee2d65db0a8a030d280ba_720w.webp) | 如果 γ=0 ，那么PReLU 就退化为ReLU；<br />Leaky ReLU 把 x 的非常小的线性分量给予<br />负输入来调整负值的零梯度问题，<br />当 x < 0 时，它得到 0.1 的正梯度。<br />一定程度上缓解了 dead ReLU 问题 |
| **ELU**        |      | <img src="C:\Users\hello\AppData\Roaming\Typora\typora-user-images\image-20230918174638338.png" alt="image-20230918174638338" style="zoom:150%;" /> | ![img](https://pic3.zhimg.com/80/v2-605fe7d42badd0d1c38b51f53461834a_720w.webp) | <br />则PReLU 可以看作Leaky ReLU;ELU 具有 ReLU 的所有优点;<br />**计算强度更高，计算量较大** |
|                |      |                                                              |                                                              |                                                              |

## 

## 四、其他

1. 
   面向对象方法中对象这一概念的理解：对象是面向对象方法学中使用的最基本的概念，对象具有一些基本特点：（1）对象以数据为中心，而不是以过程为中心，操作围绕着对其数据所需要做的处理来设置；（2）对象本质上是主动的，与传统数据有本质的不同，不是被动等待进行处理，相反，它是进行处理的主体；（3）对象实现了数据封装，一个对象类型也可以看作一种抽象数据类型；（4）对象本质上具有并行性，模块独立性比较好
2. 继承是指能够直接获得已有的性质和特征，而不必重复定义它们。继承具有传递性，一个类实际上继承了它所在的类等级中在它上层的全部基类的所有描述；当类等级为树形结构的时候，类的继承是单继承，此时一个类只允许有一个父类；继承使得相似的对象可以共享程序代码和数据结构，大大减少程序中的冗余；有了继承以后，可以把一般的已有的解法加以具体化，但是父类中自身的方法不会一起改变。
3.  **NeuralCF 模型**的相关基础知识。在实际使用矩阵分解来训练和评估模型的过程中，往往会产生的问题是欠拟合问题，原因是矩阵分解的模型结构是相对比较简单的，特别是输出层无法对优化目标进行有效的拟合，这需要模型有更加强大的表达能力，基于此动机，提出了 NeuralCF 模型来改进这个问题

#### 1.轻量化模型

##### a.定义：

轻量化模型指的是具有较小的模型体积和计算复杂度，但仍能保持较高性能的模型。轻量化模型的设计旨在解决在资源受限的设备上部署深度学习模型时的挑战，如移动设备、嵌入式系统或边缘计算设备。

##### b.实现方法：

**模型压缩：**通过减少模型中的参数数量来减小模型体积和计算复杂度。这可以通过剪枝（pruning）技术删除冗余的参数，或者通过量化（quantization）技术将浮点参数转换为低精度的定点参数来实现。

**网络结构设计：**通过设计更简单和轻量的网络结构来减小模型的复杂度。例如，使用深度可分离卷积（depthwise separable convolution）代替传统的卷积操作，或者使用轻量级的模块和块来替代复杂的模块。

**知识蒸馏：**通过将一个复杂的模型（教师模型）的知识传递给一个简化的模型（学生模型）来实现轻量化。学生模型可以通过学习教师模型的输出分布或中间表示来获得较高的性能。

**网络剪枝：**通过自动或手动的方式，剪枝掉网络中冗余的连接或节点，从而减小模型的规模和计算复杂度。剪枝可以基于权重、梯度、敏感度等准则进行。

##### **c.实例：EfficientNet、MobileNet**

- **EfficientNet：** EfficientNet是一种基于自动化模型缩放方法的轻量化模型。它通过在网络的宽度、深度和分辨率这三个维度上进行均匀的缩放来实现模型的轻量化。具体来说，EfficientNet使用了一种称为Compound Scaling的方法，通过在网络的不同层级上增加宽度系数、深度系数和分辨率系数来改变模型的规模。这种缩放方法可以在保持模型结构不变的情况下，同时提高模型的准确性和效率
-  **MobileNet：**MobileNet是一种基于深度可分离卷积的轻量化模型。它使用了两个关键的操作来减小模型的计算复杂度：深度可分离卷积和逐点卷积。深度可分离卷积将传统的卷积操作分解为深度卷积和逐点卷积两个步骤，从而减少了计算量。逐点卷积是一种只在通道维度上进行卷积的操作，可以减少卷积操作的参数数量。MobileNet通过堆叠多个深度可分离卷积层来构建轻量化模型，同时使用了全局平均池化和一些非线性激活函数来提高模型的表示能力。

#### **2.模型加速推理**

​	**<u>TensorRT</u>**是NVIDIA开发的一个用于深度学习推理加速的库，可以通过使用TensorRT来优化深度学习模型的推理过程，从而提高模型的速度和效率.

要使用TensorRT来实现模型推理加速，通常需要以下步骤：

1. 模型转换：将训练好的深度学习模型转换为TensorRT支持的格式。这可以通过使用TensorRT提供的Python API或者ONNX（开放神经网络交换格式）来实现。
2. 网络定义：使用TensorRT提供的API来定义网络结构和层次关系。这些API可以用来创建网络的输入和输出张量、添加卷积、池化和全连接层等操作。
3. 优化配置：配置TensorRT的优化参数，以便根据硬件设备和应用场景进行优化。这些参数包括推理精度、推理模式、批处理大小、内存使用等。
4. 编译模型：将定义好的网络结构和优化配置编译为TensorRT的引擎。这一步会进行一系列的优化，包括层融合、内存分配、内核选择等。
5. 执行推理：使用TensorRT引擎来进行模型推理。可以将输入数据传递给TensorRT引擎，并获取输出结果
